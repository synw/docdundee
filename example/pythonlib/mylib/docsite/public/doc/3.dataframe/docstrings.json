{
    "__init__": {
        "funcdef": "def __init__(\n\tself,\n\tdata,\n\tindex: Axes | None,\n\tcolumns: Axes | None,\n\tdtype: Dtype | None,\n\tcopy: bool | None\n) -> None",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "axes": {
        "funcdef": "def axes(\n\tself\n) -> list[Index]",
        "description": "Return a list representing the axes of the DataFrame.",
        "long_description": "It has the row axis labels and column axis labels as the only members.<br />They are returned in that order.",
        "example": {
            "code": ">>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n>>> df.axes",
            "is_executable": false,
            "description": "[RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'],\ndtype='object')]"
        },
        "params": {},
        "raises": [],
        "returns": null
    },
    "shape": {
        "funcdef": "def shape(\n\tself\n) -> tuple[int, int]",
        "description": "Return a tuple representing the dimensionality of the DataFrame.",
        "long_description": null,
        "example": {
            "code": ">>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n>>> df.shape",
            "is_executable": false,
            "description": "(2, 2)"
        },
        "params": {},
        "raises": [],
        "returns": null
    },
    "to_string": {
        "funcdef": "def to_string(\n\tself,\n\tbuf: FilePath | WriteBuffer[str] | None,\n\tcolumns: Sequence[str] | None,\n\tcol_space: int | list[int] | dict[Hashable, int] | None,\n\theader: bool | Sequence[str],\n\tindex: bool,\n\tna_rep: str,\n\tformatters: fmt.FormattersType | None,\n\tfloat_format: fmt.FloatFormatType | None,\n\tsparsify: bool | None,\n\tindex_names: bool,\n\tjustify: str | None,\n\tmax_rows: int | None,\n\tmax_cols: int | None,\n\tshow_dimensions: bool,\n\tdecimal: str,\n\tline_width: int | None,\n\tmin_rows: int | None,\n\tmax_colwidth: int | None,\n\tencoding: str | None\n) -> str | None",
        "description": "Render a DataFrame to a console-friendly tabular output.",
        "long_description": "%(shared_params)s<br />line_width : int, optional<br />    Width to wrap a line in characters.<br />min_rows : int, optional<br />    The number of rows to display in the console in a truncated repr<br />    (when number of rows is above `max_rows`).<br />max_colwidth : int, optional<br />    Max width to truncate each column in characters. By default, no limit.<br /><br />    .. versionadded:: 1.0.0<br />encoding : str, default \"utf-8\"<br />    Set character encoding.<br /><br />    .. versionadded:: 1.0<br />%(returns)s",
        "example": {
            "code": ">>> d = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}\n>>> df = pd.DataFrame(d)\n>>> print(df.to_string())",
            "is_executable": false,
            "description": "col1  col2\n0     1     4\n1     2     5\n2     3     6"
        },
        "params": {},
        "raises": [],
        "returns": null
    },
    "style": {
        "funcdef": "def style(\n\tself\n) -> Styler",
        "description": "Returns a Styler object.",
        "long_description": "Contains methods for building a styled HTML representation of the DataFrame.",
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "items": {
        "funcdef": "def items(\n\tself\n) -> Iterable[tuple[Hashable, Series]]",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "iteritems": {
        "funcdef": "def iteritems(\n\tself\n) -> Iterable[tuple[Hashable, Series]]",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "iterrows": {
        "funcdef": "def iterrows(\n\tself\n) -> Iterable[tuple[Hashable, Series]]",
        "description": "Iterate over DataFrame rows as (index, Series) pairs.",
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": {
            "name": "index",
            "type": "label or tuple of label"
        }
    },
    "itertuples": {
        "funcdef": "def itertuples(\n\tself,\n\tindex: bool,\n\tname: str | None\n) -> Iterable[tuple[Any, ...]]",
        "description": "Iterate over DataFrame rows as namedtuples.",
        "long_description": null,
        "example": {
            "code": ">>> df = pd.DataFrame({'num_legs': [4, 2], 'num_wings': [0, 2]},",
            "is_executable": false,
            "description": "...                   index=['dog', 'hawk'])"
        },
        "params": {
            "index": {
                "description": "If True, return the index as the first element of the tuple.",
                "type": "bool, default True",
                "default": null
            },
            "name": {
                "description": "The name of the returned namedtuples or None to return regular<br />tuples.",
                "type": "str or None, default \"Pandas\"",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "iterator"
        }
    },
    "dot": {
        "funcdef": "def dot(\n\tself,\n\tother: AnyArrayLike | DataFrame\n) -> DataFrame | Series",
        "description": "Compute the matrix multiplication between the DataFrame and other.",
        "long_description": "This method computes the matrix product between the DataFrame and the<br />values of an other Series, DataFrame or a numpy array.<br /><br />It can also be called using ``self @ other`` in Python >= 3.5.",
        "example": {
            "code": "Here we multiply a DataFrame with a Series.",
            "is_executable": false,
            "description": ""
        },
        "params": {
            "other": {
                "description": "The other object to compute the matrix product with.",
                "type": "Series, DataFrame or array-like",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "Series or DataFrame"
        }
    },
    "from_dict": {
        "funcdef": "def from_dict(\n\tcls,\n\tdata: dict,\n\torient: str,\n\tdtype: Dtype | None,\n\tcolumns: Axes | None\n) -> DataFrame",
        "description": "Construct DataFrame from dict of array-like or dicts.",
        "long_description": "Creates DataFrame object from dictionary by columns or by index<br />allowing dtype specification.",
        "example": {
            "code": "By default the keys of the dict become the DataFrame columns:",
            "is_executable": false,
            "description": ""
        },
        "params": {
            "data": {
                "description": "Of the form {field : array-like} or {field : dict}.",
                "type": "dict",
                "default": null
            },
            "orient": {
                "description": "The \"orientation\" of the data. If the keys of the passed dict<br />should be the columns of the resulting DataFrame, pass 'columns'<br />(default). Otherwise if the keys should be rows, pass 'index'.<br />If 'tight', assume a dict with keys ['index', 'columns', 'data',<br />'index_names', 'column_names'].<br /><br />.. versionadded:: 1.4.0<br />   'tight' as an allowed value for the ``orient`` argument",
                "type": "{'columns', 'index', 'tight'}, default 'columns'",
                "default": null
            },
            "dtype": {
                "description": "Data type to force, otherwise infer.",
                "type": "dtype, default None",
                "default": null
            },
            "columns": {
                "description": "Column labels to use when ``orient='index'``. Raises a ValueError<br />if used with ``orient='columns'`` or ``orient='tight'``.",
                "type": "list, default None",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "to_numpy": {
        "funcdef": "def to_numpy(\n\tself,\n\tdtype: npt.DTypeLike | None,\n\tcopy: bool,\n\tna_value: object\n) -> np.ndarray",
        "description": "Convert the DataFrame to a NumPy array.",
        "long_description": "By default, the dtype of the returned array will be the common NumPy<br />dtype of all types in the DataFrame. For example, if the dtypes are<br />``float16`` and ``float32``, the results dtype will be ``float32``.<br />This may require copying data and coercing values, which may be<br />expensive.",
        "example": {
            "code": ">>> pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]}).to_numpy()",
            "is_executable": false,
            "description": "array([[1, 3],\n       [2, 4]])\n\nWith heterogeneous data, the lowest common type will have to\nbe used."
        },
        "params": {
            "dtype": {
                "description": "The dtype to pass to :meth:`numpy.asarray`.",
                "type": "str or numpy.dtype",
                "default": null
            },
            "copy": {
                "description": "Whether to ensure that the returned value is not a view on<br />another array. Note that ``copy=False`` does not *ensure* that<br />``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that<br />a copy is made, even if not strictly necessary.",
                "type": "bool, default False",
                "default": null
            },
            "na_value": {
                "description": "The value to use for missing values. The default value depends<br />on `dtype` and the dtypes of the DataFrame columns.<br /><br />.. versionadded:: 1.1.0",
                "type": "Any",
                "default": "value"
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "numpy.ndarray"
        }
    },
    "to_dict": {
        "funcdef": "def to_dict(\n\tself,\n\torient: Literal['dict', 'list', 'series', 'split', 'tight', 'records', 'index'],\n\tinto: type[dict]\n) -> dict | list[dict]",
        "description": "Convert the DataFrame to a dictionary.",
        "long_description": "The type of the key-value pairs can be customized with the parameters<br />(see below).",
        "example": {
            "code": ">>> df = pd.DataFrame({'col1': [1, 2],",
            "is_executable": false,
            "description": "...                    'col2': [0.5, 0.75]},\n...                   index=['row1', 'row2'])"
        },
        "params": {
            "orient": {
                "description": "Determines the type of the values of the dictionary.<br /><br />- 'dict' (default) : dict like {column -> {index -> value}}<br />- 'list' : dict like {column -> [values]}<br />- 'series' : dict like {column -> Series(values)}<br />- 'split' : dict like<br />  {'index' -> [index], 'columns' -> [columns], 'data' -> [values]}<br />- 'tight' : dict like<br />  {'index' -> [index], 'columns' -> [columns], 'data' -> [values],<br />  'index_names' -> [index.names], 'column_names' -> [column.names]}<br />- 'records' : list like<br />  [{column -> value}, ... , {column -> value}]<br />- 'index' : dict like {index -> {column -> value}}<br /><br />Abbreviations are allowed. `s` indicates `series` and `sp`<br />indicates `split`.<br /><br />.. versionadded:: 1.4.0<br />    'tight' as an allowed value for the ``orient`` argument",
                "type": "str {'dict', 'list', 'series', 'split', 'tight', 'records', 'index'}",
                "default": null
            },
            "into": {
                "description": "The collections.abc.Mapping subclass used for all Mappings<br />in the return value.  Can be the actual class or an empty<br />instance of the mapping type you want.  If you want a<br />collections.defaultdict, you must pass it initialized.",
                "type": "class, default dict",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "dict, list or collections.abc.Mapping"
        }
    },
    "to_gbq": {
        "funcdef": "def to_gbq(\n\tself,\n\tdestination_table: str,\n\tproject_id: str | None,\n\tchunksize: int | None,\n\treauth: bool,\n\tif_exists: str,\n\tauth_local_webserver: bool,\n\ttable_schema: list[dict[str, str]] | None,\n\tlocation: str | None,\n\tprogress_bar: bool,\n\tcredentials\n) -> None",
        "description": "Write a DataFrame to a Google BigQuery table.",
        "long_description": "This function requires the `pandas-gbq package<br /><https://pandas-gbq.readthedocs.io>`__.<br /><br />See the `How to authenticate with Google BigQuery<br /><https://pandas-gbq.readthedocs.io/en/latest/howto/authentication.html>`__<br />guide for authentication instructions.",
        "example": null,
        "params": {
            "destination_table": {
                "description": "Name of table to be written, in the form ``dataset.tablename``.",
                "type": "str",
                "default": null
            },
            "project_id": {
                "description": "Google BigQuery Account project ID. Optional when available from<br />the environment.",
                "type": "str",
                "default": null
            },
            "chunksize": {
                "description": "Number of rows to be inserted in each chunk from the dataframe.<br />Set to ``None`` to load the whole dataframe at once.",
                "type": "int",
                "default": null
            },
            "reauth": {
                "description": "Force Google BigQuery to re-authenticate the user. This is useful<br />if multiple accounts are used.",
                "type": "bool, default False",
                "default": null
            },
            "if_exists": {
                "description": "Behavior when the destination table exists. Value can be one of:<br /><br />``'fail'``<br />    If table exists raise pandas_gbq.gbq.TableCreationError.<br />``'replace'``<br />    If table exists, drop it, recreate it, and insert data.<br />``'append'``<br />    If table exists, insert data. Create if does not exist.",
                "type": "str, default 'fail'",
                "default": null
            },
            "auth_local_webserver": {
                "description": "Use the `local webserver flow`_ instead of the `console flow`_<br />when getting user credentials.<br /><br />.. _local webserver flow:<br />    https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server<br />.. _console flow:<br />    https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console<br /><br />*New in version 0.2.0 of pandas-gbq*.<br /><br />.. versionchanged:: 1.5.0<br />   Default value is changed to ``True``. Google has deprecated the<br />   ``auth_local_webserver = False`` `\"out of band\" (copy-paste)<br />   flow<br />   <https://developers.googleblog.com/2022/02/making-oauth-flows-safer.html?m=1#disallowed-oob>`_.",
                "type": "bool, default True",
                "default": "value"
            },
            "table_schema": {
                "description": "List of BigQuery table fields to which according DataFrame<br />columns conform to, e.g. ``[{'name': 'col1', 'type':<br />'STRING'},...]``. If schema is not provided, it will be<br />generated according to dtypes of DataFrame columns. See<br />BigQuery API documentation on available names of a field.<br /><br />*New in version 0.3.1 of pandas-gbq*.",
                "type": "list of dicts",
                "default": null
            },
            "location": {
                "description": "Location where the load job should run. See the `BigQuery locations<br />documentation<br /><https://cloud.google.com/bigquery/docs/dataset-locations>`__ for a<br />list of available locations. The location must match that of the<br />target dataset.<br /><br />*New in version 0.5.0 of pandas-gbq*.",
                "type": "str",
                "default": null
            },
            "progress_bar": {
                "description": "Use the library `tqdm` to show the progress bar for the upload,<br />chunk by chunk.<br /><br />*New in version 0.5.0 of pandas-gbq*.",
                "type": "bool, default True",
                "default": null
            },
            "credentials": {
                "description": "Credentials for accessing Google APIs. Use this parameter to<br />override default credentials, such as to use Compute Engine<br />:class:`google.auth.compute_engine.Credentials` or Service<br />Account :class:`google.oauth2.service_account.Credentials`<br />directly.<br /><br />*New in version 0.8.0 of pandas-gbq*.",
                "type": "google.auth.credentials.Credentials",
                "default": "credentials"
            }
        },
        "raises": [],
        "returns": null
    },
    "from_records": {
        "funcdef": "def from_records(\n\tcls,\n\tdata,\n\tindex,\n\texclude,\n\tcolumns,\n\tcoerce_float: bool,\n\tnrows: int | None\n) -> DataFrame",
        "description": "Convert structured or record ndarray to DataFrame.",
        "long_description": "Creates a DataFrame object from a structured ndarray, sequence of<br />tuples or dicts, or DataFrame.",
        "example": {
            "code": "Data can be provided as a structured ndarray:",
            "is_executable": false,
            "description": ""
        },
        "params": {
            "data": {
                "description": "Structured input data.",
                "type": "structured ndarray, sequence of tuples or dicts, or DataFrame",
                "default": null
            },
            "index": {
                "description": "Field of array to use as the index, alternately a specific set of<br />input labels to use.",
                "type": "str, list of fields, array-like",
                "default": null
            },
            "exclude": {
                "description": "Columns or fields to exclude.",
                "type": "sequence, default None",
                "default": null
            },
            "columns": {
                "description": "Column names to use. If the passed data do not have names<br />associated with them, this argument provides names for the<br />columns. Otherwise this argument indicates the order of the columns<br />in the result (any names not found in the data will become all-NA<br />columns).",
                "type": "sequence, default None",
                "default": null
            },
            "coerce_float": {
                "description": "Attempt to convert values of non-string, non-numeric objects (like<br />decimal.Decimal) to floating point, useful for SQL result sets.",
                "type": "bool, default False",
                "default": null
            },
            "nrows": {
                "description": "Number of rows to read if data is an iterator.",
                "type": "int, default None",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "to_records": {
        "funcdef": "def to_records(\n\tself,\n\tindex: bool,\n\tcolumn_dtypes,\n\tindex_dtypes\n) -> np.recarray",
        "description": "Convert DataFrame to a NumPy record array.",
        "long_description": "Index will be included as the first field of the record array if<br />requested.",
        "example": {
            "code": ">>> df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]},",
            "is_executable": false,
            "description": "...                   index=['a', 'b'])"
        },
        "params": {
            "index": {
                "description": "Include index in resulting record array, stored in 'index'<br />field or using the index label, if set.",
                "type": "bool, default True",
                "default": null
            },
            "column_dtypes": {
                "description": "If a string or type, the data type to store all columns. If<br />a dictionary, a mapping of column names and indices (zero-indexed)<br />to specific data types.",
                "type": "str, type, dict, default None",
                "default": null
            },
            "index_dtypes": {
                "description": "If a string or type, the data type to store all index levels. If<br />a dictionary, a mapping of index level names and indices<br />(zero-indexed) to specific data types.<br /><br />This mapping is applied only if `index=True`.",
                "type": "str, type, dict, default None",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "numpy.recarray"
        }
    },
    "to_stata": {
        "funcdef": "def to_stata(\n\tself,\n\tpath: FilePath | WriteBuffer[bytes],\n\tconvert_dates: dict[Hashable, str] | None,\n\twrite_index: bool,\n\tbyteorder: str | None,\n\ttime_stamp: datetime.datetime | None,\n\tdata_label: str | None,\n\tvariable_labels: dict[Hashable, str] | None,\n\tversion: int | None,\n\tconvert_strl: Sequence[Hashable] | None,\n\tcompression: CompressionOptions,\n\tstorage_options: StorageOptions\n) -> None",
        "description": "Export DataFrame object to Stata dta format.",
        "long_description": "Writes the DataFrame to a Stata dataset file.<br />\"dta\" files contain a Stata dataset.",
        "example": {
            "code": ">>> df = pd.DataFrame({{'animal': ['falcon', 'parrot', 'falcon',",
            "is_executable": false,
            "description": "...                               'parrot'],\n...                    'speed': [350, 18, 361, 15]}})"
        },
        "params": {
            "path": {
                "description": "String, path object (implementing ``os.PathLike[str]``), or file-like<br />object implementing a binary ``write()`` function.<br /><br />.. versionchanged:: 1.0.0<br /><br />Previously this was \"fname\"",
                "type": "str, path object, or buffer",
                "default": null
            },
            "convert_dates": {
                "description": "Dictionary mapping columns containing datetime types to stata<br />internal format to use when writing the dates. Options are 'tc',<br />'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer<br />or a name. Datetime columns that do not have a conversion type<br />specified will be converted to 'tc'. Raises NotImplementedError if<br />a datetime column has timezone information.",
                "type": "dict",
                "default": null
            },
            "write_index": {
                "description": "Write the index to Stata dataset.",
                "type": "bool",
                "default": null
            },
            "byteorder": {
                "description": "Can be \">\", \"<\", \"little\", or \"big\". default is `sys.byteorder`.",
                "type": "str",
                "default": "is"
            },
            "time_stamp": {
                "description": "A datetime to use as file creation date.  Default is the current<br />time.",
                "type": "datetime",
                "default": "the"
            },
            "data_label": {
                "description": "A label for the data set.  Must be 80 characters or smaller.",
                "type": "str",
                "default": null
            },
            "variable_labels": {
                "description": "Dictionary containing columns as keys and variable labels as<br />values. Each label must be 80 characters or smaller.",
                "type": "dict",
                "default": null
            },
            "version": {
                "description": "Version to use in the output dta file. Set to None to let pandas<br />decide between 118 or 119 formats depending on the number of<br />columns in the frame. Version 114 can be read by Stata 10 and<br />later. Version 117 can be read by Stata 13 or later. Version 118<br />is supported in Stata 14 and later. Version 119 is supported in<br />Stata 15 and later. Version 114 limits string variables to 244<br />characters or fewer while versions 117 and later allow strings<br />with lengths up to 2,000,000 characters. Versions 118 and 119<br />support Unicode characters, and version 119 supports more than<br />32,767 variables.<br /><br />Version 119 should usually only be used when the number of<br />variables exceeds the capacity of dta format 118. Exporting<br />smaller datasets in format 119 may have unintended consequences,<br />and, as of November 2020, Stata SE cannot read version 119 files.<br /><br />.. versionchanged:: 1.0.0<br /><br />    Added support for formats 118 and 119.",
                "type": "{{114, 117, 118, 119, None}}, default 114",
                "default": null
            },
            "convert_strl": {
                "description": "List of column names to convert to string columns to Stata StrL<br />format. Only available if version is 117.  Storing strings in the<br />StrL format can produce smaller dta files if strings have more than<br />8 characters and values are repeated.",
                "type": "list",
                "default": null
            },
            "{compression_options}": {
                "description": ".. versionadded:: 1.1.0<br /><br />.. versionchanged:: 1.4.0 Zstandard support.",
                "type": null,
                "default": null
            },
            "{storage_options}": {
                "description": ".. versionadded:: 1.2.0",
                "type": null,
                "default": null
            },
            "value_labels": {
                "description": "Dictionary containing columns as keys and dictionaries of column value<br />to labels as values. Labels for a single variable must be 32,000<br />characters or smaller.<br /><br />.. versionadded:: 1.4.0",
                "type": "dict of dicts",
                "default": null
            }
        },
        "raises": [
            {
                "description": "* If datetimes contain timezone information\n* Column dtype is not representable in Stata",
                "type": "NotImplementedError"
            },
            {
                "description": "* Columns listed in convert_dates are neither datetime64[ns]\n  or datetime.datetime\n* Column listed in convert_dates is not in DataFrame\n* Categorical label contains more than 32,000 characters",
                "type": "ValueError"
            }
        ],
        "returns": null
    },
    "to_feather": {
        "funcdef": "def to_feather(\n\tself,\n\tpath: FilePath | WriteBuffer[bytes],\n\t**kwargs\n) -> None",
        "description": "Write a DataFrame to the binary Feather format.",
        "long_description": null,
        "example": null,
        "params": {
            "path": {
                "description": "String, path object (implementing ``os.PathLike[str]``), or file-like<br />object implementing a binary ``write()`` function. If a string or a path,<br />it will be used as Root Directory path when writing a partitioned dataset.",
                "type": "str, path object, file-like object",
                "default": null
            },
            "**kwargs": {
                "description": "Additional keywords passed to :func:`pyarrow.feather.write_feather`.<br />Starting with pyarrow 0.17, this includes the `compression`,<br />`compression_level`, `chunksize` and `version` keywords.<br /><br />.. versionadded:: 1.1.0",
                "type": "",
                "default": null
            }
        },
        "raises": [],
        "returns": null
    },
    "to_markdown": {
        "funcdef": "def to_markdown(\n\tself,\n\tbuf: FilePath | WriteBuffer[str] | None,\n\tmode: str,\n\tindex: bool,\n\tstorage_options: StorageOptions,\n\t**kwargs\n) -> str | None",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "to_parquet": {
        "funcdef": "def to_parquet(\n\tself,\n\tpath: FilePath | WriteBuffer[bytes] | None,\n\tengine: str,\n\tcompression: str | None,\n\tindex: bool | None,\n\tpartition_cols: list[str] | None,\n\tstorage_options: StorageOptions,\n\t**kwargs\n) -> bytes | None",
        "description": "Write a DataFrame to the binary parquet format.",
        "long_description": "This function writes the dataframe as a `parquet file<br /><https://parquet.apache.org/>`_. You can choose different parquet<br />backends, and have the option of compression. See<br />:ref:`the user guide <io.parquet>` for more details.",
        "example": {
            "code": ">>> df = pd.DataFrame(data={{'col1': [1, 2], 'col2': [3, 4]}})\n>>> df.to_parquet('df.parquet.gzip',",
            "is_executable": false,
            "description": "...               compression='gzip')  # doctest: +SKIP"
        },
        "params": {
            "path": {
                "description": "String, path object (implementing ``os.PathLike[str]``), or file-like<br />object implementing a binary ``write()`` function. If None, the result is<br />returned as bytes. If a string or path, it will be used as Root Directory<br />path when writing a partitioned dataset.<br /><br />.. versionchanged:: 1.2.0<br /><br />Previously this was \"fname\"",
                "type": "str, path object, file-like object, or None, default None",
                "default": null
            },
            "engine": {
                "description": "Parquet library to use. If 'auto', then the option<br />``io.parquet.engine`` is used. The default ``io.parquet.engine``<br />behavior is to try 'pyarrow', falling back to 'fastparquet' if<br />'pyarrow' is unavailable.",
                "type": "{{'auto', 'pyarrow', 'fastparquet'}}, default 'auto'",
                "default": null
            },
            "compression": {
                "description": "Name of the compression to use. Use ``None`` for no compression.",
                "type": "{{'snappy', 'gzip', 'brotli', None}}, default 'snappy'",
                "default": null
            },
            "index": {
                "description": "If ``True``, include the dataframe's index(es) in the file output.<br />If ``False``, they will not be written to the file.<br />If ``None``, similar to ``True`` the dataframe's index(es)<br />will be saved. However, instead of being saved as values,<br />the RangeIndex will be stored as a range in the metadata so it<br />doesn't require much space and is faster. Other indexes will<br />be included as columns in the file output.",
                "type": "bool, default None",
                "default": null
            },
            "partition_cols": {
                "description": "Column names by which to partition the dataset.<br />Columns are partitioned in the order they are given.<br />Must be None if path is not a string.",
                "type": "list, optional, default None",
                "default": null
            },
            "{storage_options}": {
                "description": ".. versionadded:: 1.2.0",
                "type": null,
                "default": null
            },
            "**kwargs": {
                "description": "Additional arguments passed to the parquet library. See<br />:ref:`pandas io <io.parquet>` for more details.",
                "type": null,
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "bytes if no path argument is provided else None"
        }
    },
    "to_orc": {
        "funcdef": "def to_orc(\n\tself,\n\tpath: FilePath | WriteBuffer[bytes] | None\n) -> bytes | None",
        "description": "Write a DataFrame to the ORC format.",
        "long_description": ".. versionadded:: 1.5.0",
        "example": {
            "code": ">>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [4, 3]})\n>>> df.to_orc('df.orc')  # doctest: +SKIP\n>>> pd.read_orc('df.orc')  # doctest: +SKIP",
            "is_executable": false,
            "description": "col1  col2\n0     1     4\n1     2     3\n\nIf you want to get a buffer to the orc content you can write it to io.BytesIO"
        },
        "params": {
            "path": {
                "description": "If a string, it will be used as Root Directory path<br />when writing a partitioned dataset. By file-like object,<br />we refer to objects with a write() method, such as a file handle<br />(e.g. via builtin open function). If path is None,<br />a bytes object is returned.",
                "type": "str, file-like object or None, default None",
                "default": null
            },
            "engine": {
                "description": "ORC library to use. Pyarrow must be >= 7.0.0.",
                "type": "str, default 'pyarrow'",
                "default": null
            },
            "index": {
                "description": "If ``True``, include the dataframe's index(es) in the file output.<br />If ``False``, they will not be written to the file.<br />If ``None``, similar to ``infer`` the dataframe's index(es)<br />will be saved. However, instead of being saved as values,<br />the RangeIndex will be stored as a range in the metadata so it<br />doesn't require much space and is faster. Other indexes will<br />be included as columns in the file output.",
                "type": "bool",
                "default": null
            },
            "engine_kwargs": {
                "description": "Additional keyword arguments passed to :func:`pyarrow.orc.write_table`.",
                "type": "dict[str, Any] or None, default None",
                "default": null
            }
        },
        "raises": [
            {
                "description": "Dtype of one or more columns is category, unsigned integers, interval,\nperiod or sparse.",
                "type": "NotImplementedError"
            },
            {
                "description": "engine is not pyarrow.",
                "type": "ValueError"
            }
        ],
        "returns": {
            "name": null,
            "type": "bytes if no path argument is provided else None"
        }
    },
    "to_html": {
        "funcdef": "def to_html(\n\tself,\n\tbuf: FilePath | WriteBuffer[str] | None,\n\tcolumns: Sequence[Level] | None,\n\tcol_space: ColspaceArgType | None,\n\theader: bool | Sequence[str],\n\tindex: bool,\n\tna_rep: str,\n\tformatters: FormattersType | None,\n\tfloat_format: FloatFormatType | None,\n\tsparsify: bool | None,\n\tindex_names: bool,\n\tjustify: str | None,\n\tmax_rows: int | None,\n\tmax_cols: int | None,\n\tshow_dimensions: bool | str,\n\tdecimal: str,\n\tbold_rows: bool,\n\tclasses: str | list | tuple | None,\n\tescape: bool,\n\tnotebook: bool,\n\tborder: int | bool | None,\n\ttable_id: str | None,\n\trender_links: bool,\n\tencoding: str | None\n) -> str | None",
        "description": "Render a DataFrame as an HTML table.",
        "long_description": "%(shared_params)s<br />bold_rows : bool, default True<br />    Make the row labels bold in the output.<br />classes : str or list or tuple, default None<br />    CSS class(es) to apply to the resulting html table.<br />escape : bool, default True<br />    Convert the characters <, >, and & to HTML-safe sequences.<br />notebook : {True, False}, default False<br />    Whether the generated HTML is for IPython Notebook.<br />border : int<br />    A ``border=border`` attribute is included in the opening<br />    `<table>` tag. Default ``pd.options.display.html.border``.<br />table_id : str, optional<br />    A css id is included in the opening `<table>` tag if specified.<br />render_links : bool, default False<br />    Convert URLs to HTML links.<br />encoding : str, default \"utf-8\"<br />    Set character encoding.<br /><br />    .. versionadded:: 1.0<br />%(returns)s",
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "to_xml": {
        "funcdef": "def to_xml(\n\tself,\n\tpath_or_buffer: FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None,\n\tindex: bool,\n\troot_name: str | None,\n\trow_name: str | None,\n\tna_rep: str | None,\n\tattr_cols: list[str] | None,\n\telem_cols: list[str] | None,\n\tnamespaces: dict[str | None, str] | None,\n\tprefix: str | None,\n\tencoding: str,\n\txml_declaration: bool | None,\n\tpretty_print: bool | None,\n\tparser: str | None,\n\tstylesheet: FilePath | ReadBuffer[str] | ReadBuffer[bytes] | None,\n\tcompression: CompressionOptions,\n\tstorage_options: StorageOptions\n) -> str | None",
        "description": "Render a DataFrame to an XML document.",
        "long_description": ".. versionadded:: 1.3.0",
        "example": {
            "code": ">>> df = pd.DataFrame({{'shape': ['square', 'circle', 'triangle'],",
            "is_executable": false,
            "description": "...                    'degrees': [360, 360, 180],\n...                    'sides': [4, np.nan, 3]}})"
        },
        "params": {
            "path_or_buffer": {
                "description": "String, path object (implementing ``os.PathLike[str]``), or file-like<br />object implementing a ``write()`` function. If None, the result is returned<br />as a string.",
                "type": "str, path object, file-like object, or None, default None",
                "default": null
            },
            "index": {
                "description": "Whether to include index in XML document.",
                "type": "bool, default True",
                "default": null
            },
            "root_name": {
                "description": "The name of root element in XML document.",
                "type": "str, default 'data'",
                "default": null
            },
            "row_name": {
                "description": "The name of row element in XML document.",
                "type": "str, default 'row'",
                "default": null
            },
            "na_rep": {
                "description": "Missing data representation.",
                "type": "str",
                "default": null
            },
            "attr_cols": {
                "description": "List of columns to write as attributes in row element.<br />Hierarchical columns will be flattened with underscore<br />delimiting the different levels.",
                "type": "list-like",
                "default": null
            },
            "elem_cols": {
                "description": "List of columns to write as children in row element. By default,<br />all columns output as children of row element. Hierarchical<br />columns will be flattened with underscore delimiting the<br />different levels.",
                "type": "list-like",
                "default": null
            },
            "namespaces": {
                "description": "All namespaces to be defined in root element. Keys of dict<br />should be prefix names and values of dict corresponding URIs.<br />Default namespaces should be given empty string key. For<br />example, ::<br /><br />    namespaces = {{\"\": \"https://example.com\"}}",
                "type": "dict",
                "default": "namespaces"
            },
            "prefix": {
                "description": "Namespace prefix to be used for every element and/or attribute<br />in document. This should be one of the keys in ``namespaces``<br />dict.",
                "type": "str",
                "default": null
            },
            "encoding": {
                "description": "Encoding of the resulting document.",
                "type": "str, default 'utf-8'",
                "default": null
            },
            "xml_declaration": {
                "description": "Whether to include the XML declaration at start of document.",
                "type": "bool, default True",
                "default": null
            },
            "pretty_print": {
                "description": "Whether output should be pretty printed with indentation and<br />line breaks.",
                "type": "bool, default True",
                "default": null
            },
            "parser": {
                "description": "Parser module to use for building of tree. Only 'lxml' and<br />'etree' are supported. With 'lxml', the ability to use XSLT<br />stylesheet is supported.",
                "type": "{{'lxml','etree'}}, default 'lxml'",
                "default": null
            },
            "stylesheet": {
                "description": "A URL, file-like object, or a raw string containing an XSLT<br />script used to transform the raw XML output. Script should use<br />layout of elements and attributes from original output. This<br />argument requires ``lxml`` to be installed. Only XSLT 1.0<br />scripts and not later versions is currently supported.",
                "type": "str, path object or file-like object",
                "default": null
            },
            "{compression_options}": {
                "description": ".. versionchanged:: 1.4.0 Zstandard support.",
                "type": null,
                "default": null
            },
            "{storage_options}": {
                "description": null,
                "type": null,
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "None or str"
        }
    },
    "info": {
        "funcdef": "def info(\n\tself,\n\tverbose: bool | None,\n\tbuf: WriteBuffer[str] | None,\n\tmax_cols: int | None,\n\tmemory_usage: bool | str | None,\n\tshow_counts: bool | None,\n\tnull_counts: bool | None\n) -> None",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "memory_usage": {
        "funcdef": "def memory_usage(\n\tself,\n\tindex: bool,\n\tdeep: bool\n) -> Series",
        "description": "Return the memory usage of each column in bytes.",
        "long_description": "The memory usage can optionally include the contribution of<br />the index and elements of `object` dtype.<br /><br />This value is displayed in `DataFrame.info` by default. This can be<br />suppressed by setting ``pandas.options.display.memory_usage`` to False.",
        "example": {
            "code": ">>> dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']\n>>> data = dict([(t, np.ones(shape=5000, dtype=int).astype(t))",
            "is_executable": false,
            "description": "...              for t in dtypes])"
        },
        "params": {
            "index": {
                "description": "Specifies whether to include the memory usage of the DataFrame's<br />index in returned Series. If ``index=True``, the memory usage of<br />the index is the first item in the output.",
                "type": "bool, default True",
                "default": null
            },
            "deep": {
                "description": "If True, introspect the data deeply by interrogating<br />`object` dtypes for system-level memory consumption, and include<br />it in the returned values.",
                "type": "bool, default False",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "Series"
        }
    },
    "transpose": {
        "funcdef": "def transpose(\n\tself,\n\t*args\n) -> DataFrame",
        "description": "Transpose index and columns.",
        "long_description": "Reflect the DataFrame over its main diagonal by writing rows as columns<br />and vice-versa. The property :attr:`.T` is an accessor to the method<br />:meth:`transpose`.",
        "example": {
            "code": "**Square DataFrame with homogeneous dtype**",
            "is_executable": false,
            "description": ""
        },
        "params": {
            "*args": {
                "description": "Accepted for compatibility with NumPy.",
                "type": "tuple",
                "default": null
            },
            "copy": {
                "description": "Whether to copy the data after transposing, even for DataFrames<br />with a single dtype.<br /><br />Note that a copy is always required for mixed dtype DataFrames,<br />or for DataFrames with any extension types.",
                "type": "bool, default False",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "T": {
        "funcdef": "def T(\n\tself\n) -> DataFrame",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "isetitem": {
        "funcdef": "def isetitem(\n\tself,\n\tloc,\n\tvalue\n) -> None",
        "description": "Set the given value in the column with position 'loc'.",
        "long_description": "This is a positional analogue to __setitem__.",
        "example": null,
        "params": {
            "loc": {
                "description": null,
                "type": "int or sequence of ints",
                "default": null
            },
            "value": {
                "description": null,
                "type": "scalar or arraylike",
                "default": null
            }
        },
        "raises": [],
        "returns": null
    },
    "query": {
        "funcdef": "def query(\n\tself,\n\texpr: str,\n\tinplace: bool,\n\t**kwargs\n) -> DataFrame | None",
        "description": "Query the columns of a DataFrame with a boolean expression.",
        "long_description": null,
        "example": {
            "code": ">>> df = pd.DataFrame({'A': range(1, 6),",
            "is_executable": false,
            "description": "...                    'B': range(10, 0, -2),\n...                    'C C': range(10, 5, -1)})"
        },
        "params": {
            "expr": {
                "description": "The query string to evaluate.<br /><br />You can refer to variables<br />in the environment by prefixing them with an '@' character like<br />``@a + b``.<br /><br />You can refer to column names that are not valid Python variable names<br />by surrounding them in backticks. Thus, column names containing spaces<br />or punctuations (besides underscores) or starting with digits must be<br />surrounded by backticks. (For example, a column named \"Area (cm^2)\" would<br />be referenced as ```Area (cm^2)```). Column names which are Python keywords<br />(like \"list\", \"for\", \"import\", etc) cannot be used.<br /><br />For example, if one of your columns is called ``a a`` and you want<br />to sum it with ``b``, your query should be ```a a` + b``.<br /><br />.. versionadded:: 0.25.0<br />    Backtick quoting introduced.<br /><br />.. versionadded:: 1.0.0<br />    Expanding functionality of backtick quoting for more than only spaces.",
                "type": "str",
                "default": null
            },
            "inplace": {
                "description": "Whether to modify the DataFrame rather than creating a new one.",
                "type": "bool",
                "default": null
            },
            "**kwargs": {
                "description": "See the documentation for :func:`eval` for complete details<br />on the keyword arguments accepted by :meth:`DataFrame.query`.",
                "type": null,
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame or None"
        }
    },
    "eval": {
        "funcdef": "def eval(\n\tself,\n\texpr: str,\n\tinplace: bool,\n\t**kwargs\n) -> Any | None",
        "description": "Evaluate a string describing operations on DataFrame columns.",
        "long_description": "Operates on columns only, not specific rows or elements.  This allows<br />`eval` to run arbitrary code, which can make you vulnerable to code<br />injection if you pass user input to this function.",
        "example": {
            "code": ">>> df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)})\n>>> df",
            "is_executable": false,
            "description": "A   B\n0  1  10\n1  2   8\n2  3   6\n3  4   4\n4  5   2"
        },
        "params": {
            "expr": {
                "description": "The expression string to evaluate.",
                "type": "str",
                "default": null
            },
            "inplace": {
                "description": "If the expression contains an assignment, whether to perform the<br />operation inplace and mutate the existing DataFrame. Otherwise,<br />a new DataFrame is returned.",
                "type": "bool, default False",
                "default": null
            },
            "**kwargs": {
                "description": "See the documentation for :func:`eval` for complete details<br />on the keyword arguments accepted by<br />:meth:`~pandas.DataFrame.query`.",
                "type": null,
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "ndarray, scalar, pandas object, or None"
        }
    },
    "select_dtypes": {
        "funcdef": "def select_dtypes(\n\tself,\n\tinclude,\n\texclude\n) -> DataFrame",
        "description": "Return a subset of the DataFrame's columns based on the column dtypes.",
        "long_description": null,
        "example": {
            "code": ">>> df = pd.DataFrame({'a': [1, 2] * 3,",
            "is_executable": false,
            "description": "...                    'b': [True, False] * 3,\n...                    'c': [1.0, 2.0] * 3})"
        },
        "params": {
            "include, exclude": {
                "description": "A selection of dtypes or strings to be included/excluded. At least<br />one of these parameters must be supplied.",
                "type": "scalar or list-like",
                "default": null
            }
        },
        "raises": [
            {
                "description": "* If both of ``include`` and ``exclude`` are empty\n* If ``include`` and ``exclude`` have overlapping elements\n* If any kind of string dtype is passed in.",
                "type": "ValueError"
            }
        ],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "insert": {
        "funcdef": "def insert(\n\tself,\n\tloc: int,\n\tcolumn: Hashable,\n\tvalue: Scalar | AnyArrayLike,\n\tallow_duplicates: bool | lib.NoDefault\n) -> None",
        "description": "Insert column into DataFrame at specified location.",
        "long_description": "Raises a ValueError if `column` is already contained in the DataFrame,<br />unless `allow_duplicates` is set to True.",
        "example": {
            "code": ">>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n>>> df",
            "is_executable": false,
            "description": "col1  col2\n0     1     3\n1     2     4"
        },
        "params": {
            "loc": {
                "description": "Insertion index. Must verify 0 <= loc <= len(columns).",
                "type": "int",
                "default": null
            },
            "column": {
                "description": "Label of the inserted column.",
                "type": "str, number, or hashable object",
                "default": null
            },
            "value": {
                "description": null,
                "type": "Scalar, Series, or array-like",
                "default": null
            },
            "allow_duplicates": {
                "description": null,
                "type": "bool, optional, default lib.no_default",
                "default": null
            }
        },
        "raises": [],
        "returns": null
    },
    "assign": {
        "funcdef": "def assign(\n\tself,\n\t**kwargs\n) -> DataFrame",
        "description": "Assign new columns to a DataFrame.",
        "long_description": "Returns a new object with all original columns in addition to new ones.<br />Existing columns that are re-assigned will be overwritten.",
        "example": {
            "code": ">>> df = pd.DataFrame({'temp_c': [17.0, 25.0]},",
            "is_executable": false,
            "description": "...                   index=['Portland', 'Berkeley'])"
        },
        "params": {
            "**kwargs": {
                "description": "The column names are keywords. If the values are<br />callable, they are computed on the DataFrame and<br />assigned to the new columns. The callable must not<br />change input DataFrame (though pandas doesn't check it).<br />If the values are not callable, (e.g. a Series, scalar, or array),<br />they are simply assigned.",
                "type": "dict of {str: callable or Series}",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "lookup": {
        "funcdef": "def lookup(\n\tself,\n\trow_labels: Sequence[IndexLabel],\n\tcol_labels: Sequence[IndexLabel]\n) -> np.ndarray",
        "description": "Label-based \"fancy indexing\" function for DataFrame.",
        "long_description": null,
        "example": null,
        "params": {
            "row_labels": {
                "description": "The row labels to use for lookup.",
                "type": "sequence",
                "default": null
            },
            "col_labels": {
                "description": "The column labels to use for lookup.",
                "type": "sequence",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "numpy.ndarray"
        }
    },
    "align": {
        "funcdef": "def align(\n\tself,\n\tother: DataFrame,\n\tjoin: Literal['outer', 'inner', 'left', 'right'],\n\taxis: Axis | None,\n\tlevel: Level,\n\tcopy: bool,\n\tfill_value,\n\tmethod: FillnaOptions | None,\n\tlimit: int | None,\n\tfill_axis: Axis,\n\tbroadcast_axis: Axis | None\n) -> DataFrame",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "set_axis": {
        "funcdef": "def set_axis(\n\tself,\n\tlabels,\n\taxis: Axis,\n\tinplace: bool | lib.NoDefault\n)",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "reindex": {
        "funcdef": "def reindex(\n\tself,\n\t*args,\n\t**kwargs\n) -> DataFrame",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "drop": {
        "funcdef": "def drop(\n\tself,\n\tlabels: IndexLabel,\n\taxis: Axis,\n\tindex: IndexLabel,\n\tcolumns: IndexLabel,\n\tlevel: Level,\n\tinplace: bool,\n\terrors: IgnoreRaise\n) -> DataFrame | None",
        "description": "Drop specified labels from rows or columns.",
        "long_description": "Remove rows or columns by specifying label names and corresponding<br />axis, or by specifying directly index or column names. When using a<br />multi-index, labels on different levels can be removed by specifying<br />the level. See the `user guide <advanced.shown_levels>`<br />for more information about the now unused levels.",
        "example": {
            "code": ">>> df = pd.DataFrame(np.arange(12).reshape(3, 4),",
            "is_executable": false,
            "description": "...                   columns=['A', 'B', 'C', 'D'])"
        },
        "params": {
            "labels": {
                "description": "Index or column labels to drop. A tuple will be used as a single<br />label and not treated as a list-like.",
                "type": "single label or list-like",
                "default": null
            },
            "axis": {
                "description": "Whether to drop labels from the index (0 or 'index') or<br />columns (1 or 'columns').",
                "type": "{0 or 'index', 1 or 'columns'}, default 0",
                "default": null
            },
            "index": {
                "description": "Alternative to specifying axis (``labels, axis=0``<br />is equivalent to ``index=labels``).",
                "type": "single label or list-like",
                "default": null
            },
            "columns": {
                "description": "Alternative to specifying axis (``labels, axis=1``<br />is equivalent to ``columns=labels``).",
                "type": "single label or list-like",
                "default": null
            },
            "level": {
                "description": "For MultiIndex, level from which the labels will be removed.",
                "type": "int or level name",
                "default": null
            },
            "inplace": {
                "description": "If False, return a copy. Otherwise, do operation<br />inplace and return None.",
                "type": "bool, default False",
                "default": null
            },
            "errors": {
                "description": "If 'ignore', suppress error and only existing labels are<br />dropped.",
                "type": "{'ignore', 'raise'}, default 'raise'",
                "default": null
            }
        },
        "raises": [
            {
                "description": "If any of the labels is not found in the selected axis.",
                "type": "KeyError"
            }
        ],
        "returns": {
            "name": null,
            "type": "DataFrame or None"
        }
    },
    "rename": {
        "funcdef": "def rename(\n\tself,\n\tmapper: Renamer | None\n) -> DataFrame | None",
        "description": "Alter axes labels.",
        "long_description": "Function / dict values must be unique (1-to-1). Labels not contained in<br />a dict / Series will be left as-is. Extra labels listed don't throw an<br />error.<br /><br />See the :ref:`user guide <basics.rename>` for more.",
        "example": {
            "code": "``DataFrame.rename`` supports two calling conventions\n\n* ``(index=index_mapper, columns=columns_mapper, ...)``\n* ``(mapper, axis={'index', 'columns'}, ...)``\n\nWe *highly* recommend using keyword arguments to clarify your\nintent.\n\nRename columns using a mapping:",
            "is_executable": false,
            "description": ""
        },
        "params": {
            "mapper": {
                "description": "Dict-like or function transformations to apply to<br />that axis' values. Use either ``mapper`` and ``axis`` to<br />specify the axis to target with ``mapper``, or ``index`` and<br />``columns``.",
                "type": "dict-like or function",
                "default": null
            },
            "index": {
                "description": "Alternative to specifying axis (``mapper, axis=0``<br />is equivalent to ``index=mapper``).",
                "type": "dict-like or function",
                "default": null
            },
            "columns": {
                "description": "Alternative to specifying axis (``mapper, axis=1``<br />is equivalent to ``columns=mapper``).",
                "type": "dict-like or function",
                "default": null
            },
            "axis": {
                "description": "Axis to target with ``mapper``. Can be either the axis name<br />('index', 'columns') or number (0, 1). The default is 'index'.",
                "type": "{0 or 'index', 1 or 'columns'}, default 0",
                "default": "is"
            },
            "copy": {
                "description": "Also copy underlying data.",
                "type": "bool, default True",
                "default": null
            },
            "inplace": {
                "description": "Whether to modify the DataFrame rather than creating a new one.<br />If True then value of copy is ignored.",
                "type": "bool, default False",
                "default": null
            },
            "level": {
                "description": "In case of a MultiIndex, only rename labels in the specified<br />level.",
                "type": "int or level name, default None",
                "default": null
            },
            "errors": {
                "description": "If 'raise', raise a `KeyError` when a dict-like `mapper`, `index`,<br />or `columns` contains labels that are not present in the Index<br />being transformed.<br />If 'ignore', existing keys will be renamed and extra keys will be<br />ignored.",
                "type": "{'ignore', 'raise'}, default 'ignore'",
                "default": null
            }
        },
        "raises": [
            {
                "description": "If any of the labels is not found in the selected axis and\n\"errors='raise'\".",
                "type": "KeyError"
            }
        ],
        "returns": {
            "name": null,
            "type": "DataFrame or None"
        }
    },
    "fillna": {
        "funcdef": "def fillna(\n\tself,\n\tvalue: Hashable | Mapping | Series | DataFrame,\n\tmethod: FillnaOptions | None,\n\taxis: Axis | None,\n\tinplace: bool,\n\tlimit: int | None,\n\tdowncast: dict | None\n) -> DataFrame | None",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "pop": {
        "funcdef": "def pop(\n\tself,\n\titem: Hashable\n) -> Series",
        "description": "Return item and drop from frame. Raise KeyError if not found.",
        "long_description": null,
        "example": {
            "code": ">>> df = pd.DataFrame([('falcon', 'bird', 389.0),",
            "is_executable": false,
            "description": "...                    ('parrot', 'bird', 24.0),\n...                    ('lion', 'mammal', 80.5),\n...                    ('monkey', 'mammal', np.nan)],\n...                   columns=('name', 'class', 'max_speed'))"
        },
        "params": {
            "item": {
                "description": "Label of column to be popped.",
                "type": "label",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "Series"
        }
    },
    "replace": {
        "funcdef": "def replace(\n\tself,\n\tto_replace,\n\tvalue,\n\tinplace: bool,\n\tlimit: int | None,\n\tregex: bool,\n\tmethod: Literal['pad', 'ffill', 'bfill'] | lib.NoDefault\n) -> DataFrame | None",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "shift": {
        "funcdef": "def shift(\n\tself,\n\tperiods: int,\n\tfreq: Frequency | None,\n\taxis: Axis,\n\tfill_value: Hashable\n) -> DataFrame",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "set_index": {
        "funcdef": "def set_index(\n\tself,\n\tkeys,\n\tdrop: bool,\n\tappend: bool,\n\tinplace: bool,\n\tverify_integrity: bool\n) -> DataFrame | None",
        "description": "Set the DataFrame index using existing columns.",
        "long_description": "Set the DataFrame index (row labels) using one or more existing<br />columns or arrays (of the correct length). The index can replace the<br />existing index or expand on it.",
        "example": {
            "code": ">>> df = pd.DataFrame({'month': [1, 4, 7, 10],",
            "is_executable": false,
            "description": "...                    'year': [2012, 2014, 2013, 2014],\n...                    'sale': [55, 40, 84, 31]})"
        },
        "params": {
            "keys": {
                "description": "This parameter can be either a single column key, a single array of<br />the same length as the calling DataFrame, or a list containing an<br />arbitrary combination of column keys and arrays. Here, \"array\"<br />encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and<br />instances of :class:`~collections.abc.Iterator`.",
                "type": "label or array-like or list of labels/arrays",
                "default": null
            },
            "drop": {
                "description": "Delete columns to be used as the new index.",
                "type": "bool, default True",
                "default": null
            },
            "append": {
                "description": "Whether to append columns to existing index.",
                "type": "bool, default False",
                "default": null
            },
            "inplace": {
                "description": "Whether to modify the DataFrame rather than creating a new one.",
                "type": "bool, default False",
                "default": null
            },
            "verify_integrity": {
                "description": "Check the new index for duplicates. Otherwise defer the check until<br />necessary. Setting to False will improve the performance of this<br />method.",
                "type": "bool, default False",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame or None"
        }
    },
    "reset_index": {
        "funcdef": "def reset_index(\n\tself,\n\tlevel: IndexLabel,\n\tdrop: bool,\n\tinplace: bool,\n\tcol_level: Hashable,\n\tcol_fill: Hashable,\n\tallow_duplicates: bool | lib.NoDefault,\n\tnames: Hashable | Sequence[Hashable]\n) -> DataFrame | None",
        "description": "Reset the index, or a level of it.",
        "long_description": "Reset the index of the DataFrame, and use the default one instead.<br />If the DataFrame has a MultiIndex, this method can remove one or more<br />levels.",
        "example": {
            "code": ">>> df = pd.DataFrame([('bird', 389.0),",
            "is_executable": false,
            "description": "...                    ('bird', 24.0),\n...                    ('mammal', 80.5),\n...                    ('mammal', np.nan)],\n...                   index=['falcon', 'parrot', 'lion', 'monkey'],\n...                   columns=('class', 'max_speed'))"
        },
        "params": {
            "level": {
                "description": "Only remove the given levels from the index. Removes all levels by<br />default.",
                "type": "int, str, tuple, or list, default None",
                "default": null
            },
            "drop": {
                "description": "Do not try to insert index into dataframe columns. This resets<br />the index to the default integer index.",
                "type": "bool, default False",
                "default": "integer"
            },
            "inplace": {
                "description": "Whether to modify the DataFrame rather than creating a new one.",
                "type": "bool, default False",
                "default": null
            },
            "col_level": {
                "description": "If the columns have multiple levels, determines which level the<br />labels are inserted into. By default it is inserted into the first<br />level.",
                "type": "int or str, default 0",
                "default": "it"
            },
            "col_fill": {
                "description": "If the columns have multiple levels, determines how the other<br />levels are named. If None then the index name is repeated.",
                "type": "object, default ''",
                "default": null
            },
            "allow_duplicates": {
                "description": "Allow duplicate column labels to be created.<br /><br />.. versionadded:: 1.5.0",
                "type": "bool, optional, default lib.no_default",
                "default": null
            },
            "names": {
                "description": "Using the given string, rename the DataFrame column which contains the<br />index data. If the DataFrame has a MultiIndex, this has to be a list or<br />tuple with length equal to the number of levels.<br /><br />.. versionadded:: 1.5.0",
                "type": "int, str or 1-dimensional list, default None",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame or None"
        }
    },
    "isna": {
        "funcdef": "def isna(\n\tself\n) -> DataFrame",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "isnull": {
        "funcdef": "def isnull(\n\tself\n) -> DataFrame",
        "description": "DataFrame.isnull is an alias for DataFrame.isna.",
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "notna": {
        "funcdef": "def notna(\n\tself\n) -> DataFrame",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "notnull": {
        "funcdef": "def notnull(\n\tself\n) -> DataFrame",
        "description": "DataFrame.notnull is an alias for DataFrame.notna.",
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "dropna": {
        "funcdef": "def dropna(\n\tself,\n\taxis: Axis,\n\thow: str | NoDefault,\n\tthresh: int | NoDefault,\n\tsubset: IndexLabel,\n\tinplace: bool\n) -> DataFrame | None",
        "description": "Remove missing values.",
        "long_description": "See the :ref:`User Guide <missing_data>` for more on which values are<br />considered missing, and how to work with missing data.",
        "example": {
            "code": ">>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],",
            "is_executable": false,
            "description": "...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n...                             pd.NaT]})"
        },
        "params": {
            "axis": {
                "description": "Determine if rows or columns which contain missing values are<br />removed.<br /><br />* 0, or 'index' : Drop rows which contain missing values.<br />* 1, or 'columns' : Drop columns which contain missing value.<br /><br />.. versionchanged:: 1.0.0<br /><br />   Pass tuple or list to drop on multiple axes.<br />   Only a single axis is allowed.",
                "type": "{0 or 'index', 1 or 'columns'}, default 0",
                "default": null
            },
            "how": {
                "description": "Determine if row or column is removed from DataFrame, when we have<br />at least one NA or all NA.<br /><br />* 'any' : If any NA values are present, drop that row or column.<br />* 'all' : If all values are NA, drop that row or column.",
                "type": "{'any', 'all'}, default 'any'",
                "default": null
            },
            "thresh": {
                "description": "Require that many non-NA values. Cannot be combined with how.",
                "type": "int",
                "default": null
            },
            "subset": {
                "description": "Labels along other axis to consider, e.g. if you are dropping rows<br />these would be a list of columns to include.",
                "type": "column label or sequence of labels",
                "default": null
            },
            "inplace": {
                "description": "Whether to modify the DataFrame rather than creating a new one.",
                "type": "bool, default False",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame or None"
        }
    },
    "drop_duplicates": {
        "funcdef": "def drop_duplicates(\n\tself,\n\tsubset: Hashable | Sequence[Hashable] | None,\n\tkeep: Literal['first', 'last', False],\n\tinplace: bool,\n\tignore_index: bool\n) -> DataFrame | None",
        "description": "Return DataFrame with duplicate rows removed.",
        "long_description": "Considering certain columns is optional. Indexes, including time indexes<br />are ignored.",
        "example": {
            "code": "Consider dataset containing ramen rating.",
            "is_executable": false,
            "description": ""
        },
        "params": {
            "subset": {
                "description": "Only consider certain columns for identifying duplicates, by<br />default use all of the columns.",
                "type": "column label or sequence of labels",
                "default": "use"
            },
            "keep": {
                "description": "Determines which duplicates (if any) to keep.<br />- ``first`` : Drop duplicates except for the first occurrence.<br />- ``last`` : Drop duplicates except for the last occurrence.<br />- False : Drop all duplicates.",
                "type": "{'first', 'last', False}, default 'first'",
                "default": null
            },
            "inplace": {
                "description": "Whether to modify the DataFrame rather than creating a new one.",
                "type": "bool, default False",
                "default": null
            },
            "ignore_index": {
                "description": "If True, the resulting axis will be labeled 0, 1, \u2026, n - 1.<br /><br />.. versionadded:: 1.0.0",
                "type": "bool, default False",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame or None"
        }
    },
    "duplicated": {
        "funcdef": "def duplicated(\n\tself,\n\tsubset: Hashable | Sequence[Hashable] | None,\n\tkeep: Literal['first', 'last', False]\n) -> Series",
        "description": "Return boolean Series denoting duplicate rows.",
        "long_description": "Considering certain columns is optional.",
        "example": {
            "code": "Consider dataset containing ramen rating.",
            "is_executable": false,
            "description": ""
        },
        "params": {
            "subset": {
                "description": "Only consider certain columns for identifying duplicates, by<br />default use all of the columns.",
                "type": "column label or sequence of labels",
                "default": "use"
            },
            "keep": {
                "description": "Determines which duplicates (if any) to mark.<br /><br />- ``first`` : Mark duplicates as ``True`` except for the first occurrence.<br />- ``last`` : Mark duplicates as ``True`` except for the last occurrence.<br />- False : Mark all duplicates as ``True``.",
                "type": "{'first', 'last', False}, default 'first'",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "Series"
        }
    },
    "sort_values": {
        "funcdef": "def sort_values(\n\tself,\n\tby: IndexLabel,\n\taxis: Axis,\n\tascending: bool | list[bool] | tuple[bool, ...],\n\tinplace: bool,\n\tkind: str,\n\tna_position: str,\n\tignore_index: bool,\n\tkey: ValueKeyFunc\n) -> DataFrame | None",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "sort_index": {
        "funcdef": "def sort_index(\n\tself,\n\taxis: Axis,\n\tlevel: IndexLabel,\n\tascending: bool | Sequence[bool],\n\tinplace: bool,\n\tkind: SortKind,\n\tna_position: NaPosition,\n\tsort_remaining: bool,\n\tignore_index: bool,\n\tkey: IndexKeyFunc\n) -> DataFrame | None",
        "description": "Sort object by labels (along an axis).",
        "long_description": "Returns a new DataFrame sorted by label if `inplace` argument is<br />``False``, otherwise updates the original DataFrame and returns None.",
        "example": {
            "code": ">>> df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150],",
            "is_executable": false,
            "description": "...                   columns=['A'])"
        },
        "params": {
            "axis": {
                "description": "The axis along which to sort.  The value 0 identifies the rows,<br />and 1 identifies the columns.",
                "type": "{0 or 'index', 1 or 'columns'}, default 0",
                "default": null
            },
            "level": {
                "description": "If not None, sort on values in specified index level(s).",
                "type": "int or level name or list of ints or list of level names",
                "default": null
            },
            "ascending": {
                "description": "Sort ascending vs. descending. When the index is a MultiIndex the<br />sort direction can be controlled for each level individually.",
                "type": "bool or list-like of bools, default True",
                "default": null
            },
            "inplace": {
                "description": "Whether to modify the DataFrame rather than creating a new one.",
                "type": "bool, default False",
                "default": null
            },
            "kind": {
                "description": "Choice of sorting algorithm. See also :func:`numpy.sort` for more<br />information. `mergesort` and `stable` are the only stable algorithms. For<br />DataFrames, this option is only applied when sorting on a single<br />column or label.",
                "type": "{'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'",
                "default": null
            },
            "na_position": {
                "description": "Puts NaNs at the beginning if `first`; `last` puts NaNs at the end.<br />Not implemented for MultiIndex.",
                "type": "{'first', 'last'}, default 'last'",
                "default": null
            },
            "sort_remaining": {
                "description": "If True and sorting by level and index is multilevel, sort by other<br />levels too (in order) after sorting by specified level.",
                "type": "bool, default True",
                "default": null
            },
            "ignore_index": {
                "description": "If True, the resulting axis will be labeled 0, 1, \u2026, n - 1.<br /><br />.. versionadded:: 1.0.0",
                "type": "bool, default False",
                "default": null
            },
            "key": {
                "description": "If not None, apply the key function to the index values<br />before sorting. This is similar to the `key` argument in the<br />builtin :meth:`sorted` function, with the notable difference that<br />this `key` function should be *vectorized*. It should expect an<br />``Index`` and return an ``Index`` of the same shape. For MultiIndex<br />inputs, the key is applied *per level*.<br /><br />.. versionadded:: 1.1.0",
                "type": "callable",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame or None"
        }
    },
    "value_counts": {
        "funcdef": "def value_counts(\n\tself,\n\tsubset: Sequence[Hashable] | None,\n\tnormalize: bool,\n\tsort: bool,\n\tascending: bool,\n\tdropna: bool\n) -> Series",
        "description": "Return a Series containing counts of unique rows in the DataFrame.",
        "long_description": ".. versionadded:: 1.1.0",
        "example": {
            "code": ">>> df = pd.DataFrame({'num_legs': [2, 4, 4, 6],",
            "is_executable": false,
            "description": "...                    'num_wings': [2, 0, 0, 0]},\n...                   index=['falcon', 'dog', 'cat', 'ant'])"
        },
        "params": {
            "subset": {
                "description": "Columns to use when counting unique combinations.",
                "type": "list-like",
                "default": null
            },
            "normalize": {
                "description": "Return proportions rather than frequencies.",
                "type": "bool, default False",
                "default": null
            },
            "sort": {
                "description": "Sort by frequencies.",
                "type": "bool, default True",
                "default": null
            },
            "ascending": {
                "description": "Sort in ascending order.",
                "type": "bool, default False",
                "default": null
            },
            "dropna": {
                "description": "Don\u2019t include counts of rows that contain NA values.<br /><br />.. versionadded:: 1.3.0",
                "type": "bool, default True",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "Series"
        }
    },
    "nlargest": {
        "funcdef": "def nlargest(\n\tself,\n\tn: int,\n\tcolumns: IndexLabel,\n\tkeep: str\n) -> DataFrame",
        "description": "Return the first `n` rows ordered by `columns` in descending order.",
        "long_description": "Return the first `n` rows with the largest values in `columns`, in<br />descending order. The columns that are not specified are returned as<br />well, but not used for ordering.<br /><br />This method is equivalent to<br />``df.sort_values(columns, ascending=False).head(n)``, but more<br />performant.",
        "example": {
            "code": ">>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,",
            "is_executable": false,
            "description": "...                                   434000, 434000, 337000, 11300,\n...                                   11300, 11300],\n...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n...                            17036, 182, 38, 311],\n...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n...                   index=[\"Italy\", \"France\", \"Malta\",\n...                          \"Maldives\", \"Brunei\", \"Iceland\",\n...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])"
        },
        "params": {
            "n": {
                "description": "Number of rows to return.",
                "type": "int",
                "default": null
            },
            "columns": {
                "description": "Column label(s) to order by.",
                "type": "label or list of labels",
                "default": null
            },
            "keep": {
                "description": "Where there are duplicate values:<br /><br />- ``first`` : prioritize the first occurrence(s)<br />- ``last`` : prioritize the last occurrence(s)<br />- ``all`` : do not drop any duplicates, even it means<br />  selecting more than `n` items.",
                "type": "{'first', 'last', 'all'}, default 'first'",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "nsmallest": {
        "funcdef": "def nsmallest(\n\tself,\n\tn: int,\n\tcolumns: IndexLabel,\n\tkeep: str\n) -> DataFrame",
        "description": "Return the first `n` rows ordered by `columns` in ascending order.",
        "long_description": "Return the first `n` rows with the smallest values in `columns`, in<br />ascending order. The columns that are not specified are returned as<br />well, but not used for ordering.<br /><br />This method is equivalent to<br />``df.sort_values(columns, ascending=True).head(n)``, but more<br />performant.",
        "example": {
            "code": ">>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,",
            "is_executable": false,
            "description": "...                                   434000, 434000, 337000, 337000,\n...                                   11300, 11300],\n...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n...                            17036, 182, 38, 311],\n...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n...                   index=[\"Italy\", \"France\", \"Malta\",\n...                          \"Maldives\", \"Brunei\", \"Iceland\",\n...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])"
        },
        "params": {
            "n": {
                "description": "Number of items to retrieve.",
                "type": "int",
                "default": null
            },
            "columns": {
                "description": "Column name or names to order by.",
                "type": "list or str",
                "default": null
            },
            "keep": {
                "description": "Where there are duplicate values:<br /><br />- ``first`` : take the first occurrence.<br />- ``last`` : take the last occurrence.<br />- ``all`` : do not drop any duplicates, even it means<br />  selecting more than `n` items.",
                "type": "{'first', 'last', 'all'}, default 'first'",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "swaplevel": {
        "funcdef": "def swaplevel(\n\tself,\n\ti: Axis,\n\tj: Axis,\n\taxis: Axis\n) -> DataFrame",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "reorder_levels": {
        "funcdef": "def reorder_levels(\n\tself,\n\torder: Sequence[Axis],\n\taxis: Axis\n) -> DataFrame",
        "description": "Rearrange index levels using input order. May not drop or duplicate levels.",
        "long_description": null,
        "example": {
            "code": ">>> data = {",
            "is_executable": false,
            "description": "...     \"class\": [\"Mammals\", \"Mammals\", \"Reptiles\"],\n...     \"diet\": [\"Omnivore\", \"Carnivore\", \"Carnivore\"],\n...     \"species\": [\"Humans\", \"Dogs\", \"Snakes\"],\n... }"
        },
        "params": {
            "order": {
                "description": "List representing new level order. Reference level by number<br />(position) or by key (label).",
                "type": "list of int or list of str",
                "default": null
            },
            "axis": {
                "description": "Where to reorder levels.",
                "type": "{0 or 'index', 1 or 'columns'}, default 0",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "compare": {
        "funcdef": "def compare(\n\tself,\n\tother: DataFrame,\n\talign_axis: Axis,\n\tkeep_shape: bool,\n\tkeep_equal: bool,\n\tresult_names: Suffixes\n) -> DataFrame",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "combine": {
        "funcdef": "def combine(\n\tself,\n\tother: DataFrame,\n\tfunc: Callable[[Series, Series], Series | Hashable],\n\tfill_value,\n\toverwrite: bool\n) -> DataFrame",
        "description": "Perform column-wise combine with another DataFrame.",
        "long_description": "Combines a DataFrame with `other` DataFrame using `func`<br />to element-wise combine columns. The row and column indexes of the<br />resulting DataFrame will be the union of the two.",
        "example": {
            "code": "Combine using a simple function that chooses the smaller column.",
            "is_executable": false,
            "description": ""
        },
        "params": {
            "other": {
                "description": "The DataFrame to merge column-wise.",
                "type": "DataFrame",
                "default": null
            },
            "func": {
                "description": "Function that takes two series as inputs and return a Series or a<br />scalar. Used to merge the two dataframes column by columns.",
                "type": "function",
                "default": null
            },
            "fill_value": {
                "description": "The value to fill NaNs with prior to passing any column to the<br />merge func.",
                "type": "scalar value, default None",
                "default": null
            },
            "overwrite": {
                "description": "If True, columns in `self` that do not exist in `other` will be<br />overwritten with NaNs.",
                "type": "bool, default True",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "combine_first": {
        "funcdef": "def combine_first(\n\tself,\n\tother: DataFrame\n) -> DataFrame",
        "description": "Update null elements with value in the same location in `other`.",
        "long_description": "Combine two DataFrame objects by filling null values in one DataFrame<br />with non-null values from other DataFrame. The row and column indexes<br />of the resulting DataFrame will be the union of the two. The resulting<br />dataframe contains the 'first' dataframe values and overrides the<br />second one values where both first.loc[index, col] and<br />second.loc[index, col] are not missing values, upon calling<br />first.combine_first(second).",
        "example": {
            "code": ">>> df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})\n>>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n>>> df1.combine_first(df2)",
            "is_executable": false,
            "description": "A    B\n0  1.0  3.0\n1  0.0  4.0\n\nNull values still persist if the location of that null value\ndoes not exist in `other`"
        },
        "params": {
            "other": {
                "description": "Provided DataFrame to use to fill null values.",
                "type": "DataFrame",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "update": {
        "funcdef": "def update(\n\tself,\n\tother,\n\tjoin: str,\n\toverwrite: bool,\n\tfilter_func,\n\terrors: str\n) -> None",
        "description": "Modify in place using non-NA values from another DataFrame.",
        "long_description": "Aligns on indices. There is no return value.",
        "example": {
            "code": ">>> df = pd.DataFrame({'A': [1, 2, 3],",
            "is_executable": false,
            "description": "...                    'B': [400, 500, 600]})"
        },
        "params": {
            "other": {
                "description": "Should have at least one matching index/column label<br />with the original DataFrame. If a Series is passed,<br />its name attribute must be set, and that will be<br />used as the column name to align with the original DataFrame.",
                "type": "DataFrame, or object coercible into a DataFrame",
                "default": null
            },
            "join": {
                "description": "Only left join is implemented, keeping the index and columns of the<br />original object.",
                "type": "{'left'}, default 'left'",
                "default": null
            },
            "overwrite": {
                "description": "How to handle non-NA values for overlapping keys:<br /><br />* True: overwrite original DataFrame's values<br />  with values from `other`.<br />* False: only update values that are NA in<br />  the original DataFrame.",
                "type": "bool, default True",
                "default": null
            },
            "filter_func": {
                "description": "Can choose to replace values other than NA. Return True for values<br />that should be updated.",
                "type": "callable(1d-array) -> bool 1d-array",
                "default": null
            },
            "errors": {
                "description": "If 'raise', will raise a ValueError if the DataFrame and `other`<br />both contain non-NA data in the same place.",
                "type": "{'raise', 'ignore'}, default 'ignore'",
                "default": null
            }
        },
        "raises": [
            {
                "description": "* When `errors='raise'` and there's overlapping non-NA data.\n* When `errors` is not either `'ignore'` or `'raise'`",
                "type": "ValueError"
            },
            {
                "description": "* If `join != 'left'`",
                "type": "NotImplementedError"
            }
        ],
        "returns": {
            "name": "None",
            "type": "method directly changes calling object"
        }
    },
    "groupby": {
        "funcdef": "def groupby(\n\tself,\n\tby,\n\taxis: Axis,\n\tlevel: IndexLabel | None,\n\tas_index: bool,\n\tsort: bool,\n\tgroup_keys: bool | lib.NoDefault,\n\tsqueeze: bool | lib.NoDefault,\n\tobserved: bool,\n\tdropna: bool\n) -> DataFrameGroupBy",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "pivot": {
        "funcdef": "def pivot(\n\tself,\n\tindex,\n\tcolumns,\n\tvalues\n) -> DataFrame",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "pivot_table": {
        "funcdef": "def pivot_table(\n\tself,\n\tvalues,\n\tindex,\n\tcolumns,\n\taggfunc,\n\tfill_value,\n\tmargins,\n\tdropna,\n\tmargins_name,\n\tobserved,\n\tsort\n) -> DataFrame",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "stack": {
        "funcdef": "def stack(\n\tself,\n\tlevel: Level,\n\tdropna: bool\n)",
        "description": "Stack the prescribed level(s) from columns to index.",
        "long_description": "Return a reshaped DataFrame or Series having a multi-level<br />index with one or more new inner-most levels compared to the current<br />DataFrame. The new inner-most levels are created by pivoting the<br />columns of the current dataframe:<br /><br />  - if the columns have a single level, the output is a Series;<br />  - if the columns have multiple levels, the new index<br />    level(s) is (are) taken from the prescribed level(s) and<br />    the output is a DataFrame.",
        "example": {
            "code": "**Single level columns**",
            "is_executable": false,
            "description": ""
        },
        "params": {
            "level": {
                "description": "Level(s) to stack from the column axis onto the index<br />axis, defined as one index or label, or a list of indices<br />or labels.",
                "type": "int, str, list, default -1",
                "default": null
            },
            "dropna": {
                "description": "Whether to drop rows in the resulting Frame/Series with<br />missing values. Stacking a column level onto the index<br />axis can create combinations of index and column values<br />that are missing from the original dataframe. See Examples<br />section.",
                "type": "bool, default True",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame or Series"
        }
    },
    "explode": {
        "funcdef": "def explode(\n\tself,\n\tcolumn: IndexLabel,\n\tignore_index: bool\n) -> DataFrame",
        "description": "Transform each element of a list-like to a row, replicating index values.",
        "long_description": ".. versionadded:: 0.25.0",
        "example": {
            "code": ">>> df = pd.DataFrame({'A': [[0, 1, 2], 'foo', [], [3, 4]],",
            "is_executable": false,
            "description": "...                    'B': 1,\n...                    'C': [['a', 'b', 'c'], np.nan, [], ['d', 'e']]})"
        },
        "params": {
            "column": {
                "description": "Column(s) to explode.<br />For multiple columns, specify a non-empty list with each element<br />be str or tuple, and all specified columns their list-like data<br />on same row of the frame must have matching length.<br /><br />.. versionadded:: 1.3.0<br />    Multi-column explode",
                "type": "IndexLabel",
                "default": null
            },
            "ignore_index": {
                "description": "If True, the resulting index will be labeled 0, 1, \u2026, n - 1.<br /><br />.. versionadded:: 1.1.0",
                "type": "bool, default False",
                "default": null
            }
        },
        "raises": [
            {
                "description": "* If columns of the frame are not unique.\n* If specified columns to explode is empty list.\n* If specified columns to explode have not matching count of\n  elements rowwise in the frame.",
                "type": "ValueError :"
            }
        ],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "unstack": {
        "funcdef": "def unstack(\n\tself,\n\tlevel: Level,\n\tfill_value\n)",
        "description": "Pivot a level of the (necessarily hierarchical) index labels.",
        "long_description": "Returns a DataFrame having a new level of column labels whose inner-most level<br />consists of the pivoted index labels.<br /><br />If the index is not a MultiIndex, the output will be a Series<br />(the analogue of stack when the columns are not a MultiIndex).",
        "example": {
            "code": ">>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),",
            "is_executable": false,
            "description": "...                                    ('two', 'a'), ('two', 'b')])"
        },
        "params": {
            "level": {
                "description": "Level(s) of index to unstack, can pass level name.",
                "type": "int, str, or list of these, default -1 (last level)",
                "default": null
            },
            "fill_value": {
                "description": "Replace NaN with this value if the unstack produces missing values.",
                "type": "int, str or dict",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "Series or DataFrame"
        }
    },
    "melt": {
        "funcdef": "def melt(\n\tself,\n\tid_vars,\n\tvalue_vars,\n\tvar_name,\n\tvalue_name,\n\tcol_level: Level,\n\tignore_index: bool\n) -> DataFrame",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "diff": {
        "funcdef": "def diff(\n\tself,\n\tperiods: int,\n\taxis: Axis\n) -> DataFrame",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "aggregate": {
        "funcdef": "def aggregate(\n\tself,\n\tfunc,\n\taxis: Axis,\n\t*args,\n\t**kwargs\n)",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "any": {
        "funcdef": "def any(\n\tself,\n\taxis: Axis,\n\tbool_only: bool | None,\n\tskipna: bool,\n\tlevel: Level,\n\t**kwargs\n) -> DataFrame | Series",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "transform": {
        "funcdef": "def transform(\n\tself,\n\tfunc: AggFuncType,\n\taxis: Axis,\n\t*args,\n\t**kwargs\n) -> DataFrame",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "apply": {
        "funcdef": "def apply(\n\tself,\n\tfunc: AggFuncType,\n\taxis: Axis,\n\traw: bool,\n\tresult_type: Literal['expand', 'reduce', 'broadcast'] | None,\n\targs,\n\t**kwargs\n)",
        "description": "Apply a function along an axis of the DataFrame.",
        "long_description": "Objects passed to the function are Series objects whose index is<br />either the DataFrame's index (``axis=0``) or the DataFrame's columns<br />(``axis=1``). By default (``result_type=None``), the final return type<br />is inferred from the return type of the applied function. Otherwise,<br />it depends on the `result_type` argument.",
        "example": {
            "code": ">>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n>>> df",
            "is_executable": false,
            "description": "A  B\n0  4  9\n1  4  9\n2  4  9\n\nUsing a numpy universal function (in this case the same as\n``np.sqrt(df)``):"
        },
        "params": {
            "func": {
                "description": "Function to apply to each column or row.",
                "type": "function",
                "default": null
            },
            "axis": {
                "description": "Axis along which the function is applied:<br /><br />* 0 or 'index': apply function to each column.<br />* 1 or 'columns': apply function to each row.",
                "type": "{0 or 'index', 1 or 'columns'}, default 0",
                "default": null
            },
            "raw": {
                "description": "Determines if row or column is passed as a Series or ndarray object:<br /><br />* ``False`` : passes each row or column as a Series to the<br />  function.<br />* ``True`` : the passed function will receive ndarray objects<br />  instead.<br />  If you are just applying a NumPy reduction function this will<br />  achieve much better performance.",
                "type": "bool, default False",
                "default": null
            },
            "result_type": {
                "description": "These only act when ``axis=1`` (columns):<br /><br />* 'expand' : list-like results will be turned into columns.<br />* 'reduce' : returns a Series if possible rather than expanding<br />  list-like results. This is the opposite of 'expand'.<br />* 'broadcast' : results will be broadcast to the original shape<br />  of the DataFrame, the original index and columns will be<br />  retained.<br /><br />The default behaviour (None) depends on the return value of the<br />applied function: list-like results will be returned as a Series<br />of those. However if the apply function returns a Series these<br />are expanded to columns.",
                "type": "{'expand', 'reduce', 'broadcast', None}, default None",
                "default": "behaviour"
            },
            "args": {
                "description": "Positional arguments to pass to `func` in addition to the<br />array/series.",
                "type": "tuple",
                "default": null
            },
            "**kwargs": {
                "description": "Additional keyword arguments to pass as keywords arguments to<br />`func`.",
                "type": null,
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "Series or DataFrame"
        }
    },
    "applymap": {
        "funcdef": "def applymap(\n\tself,\n\tfunc: PythonFuncType,\n\tna_action: str | None,\n\t**kwargs\n) -> DataFrame",
        "description": "Apply a function to a Dataframe elementwise.",
        "long_description": "This method applies a function that accepts and returns a scalar<br />to every element of a DataFrame.",
        "example": {
            "code": ">>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n>>> df",
            "is_executable": false,
            "description": "0      1\n0  1.000  2.120\n1  3.356  4.567"
        },
        "params": {
            "func": {
                "description": "Python function, returns a single value from a single value.",
                "type": "callable",
                "default": null
            },
            "na_action": {
                "description": "If \u2018ignore\u2019, propagate NaN values, without passing them to func.<br /><br />.. versionadded:: 1.2",
                "type": "{None, 'ignore'}, default None",
                "default": null
            },
            "**kwargs": {
                "description": "Additional keyword arguments to pass as keywords arguments to<br />`func`.<br /><br />.. versionadded:: 1.3.0",
                "type": null,
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "append": {
        "funcdef": "def append(\n\tself,\n\tother,\n\tignore_index: bool,\n\tverify_integrity: bool,\n\tsort: bool\n) -> DataFrame",
        "description": "Append rows of `other` to the end of caller, returning a new object.",
        "long_description": null,
        "example": {
            "code": ">>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'), index=['x', 'y'])\n>>> df",
            "is_executable": false,
            "description": "A  B\nx  1  2\ny  3  4"
        },
        "params": {
            "other": {
                "description": "The data to append.",
                "type": "DataFrame or Series/dict-like object, or list of these",
                "default": null
            },
            "ignore_index": {
                "description": "If True, the resulting axis will be labeled 0, 1, \u2026, n - 1.",
                "type": "bool, default False",
                "default": null
            },
            "verify_integrity": {
                "description": "If True, raise ValueError on creating index with duplicates.",
                "type": "bool, default False",
                "default": null
            },
            "sort": {
                "description": "Sort columns if the columns of `self` and `other` are not aligned.<br /><br />.. versionchanged:: 1.0.0<br /><br />    Changed to not sort by default.",
                "type": "bool, default False",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "join": {
        "funcdef": "def join(\n\tself,\n\tother: DataFrame | Series | list[DataFrame | Series],\n\ton: IndexLabel | None,\n\thow: str,\n\tlsuffix: str,\n\trsuffix: str,\n\tsort: bool,\n\tvalidate: str | None\n) -> DataFrame",
        "description": "Join columns of another DataFrame.",
        "long_description": "Join columns with `other` DataFrame either on index or on a key<br />column. Efficiently join multiple DataFrame objects by index at once by<br />passing a list.",
        "example": {
            "code": ">>> df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],",
            "is_executable": false,
            "description": "...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})"
        },
        "params": {
            "other": {
                "description": "Index should be similar to one of the columns in this one. If a<br />Series is passed, its name attribute must be set, and that will be<br />used as the column name in the resulting joined DataFrame.",
                "type": "DataFrame, Series, or a list containing any combination of them",
                "default": null
            },
            "on": {
                "description": "Column or index level name(s) in the caller to join on the index<br />in `other`, otherwise joins index-on-index. If multiple<br />values given, the `other` DataFrame must have a MultiIndex. Can<br />pass an array as the join key if it is not already contained in<br />the calling DataFrame. Like an Excel VLOOKUP operation.",
                "type": "str, list of str, or array-like",
                "default": null
            },
            "how": {
                "description": "How to handle the operation of the two objects.<br /><br />* left: use calling frame's index (or column if on is specified)<br />* right: use `other`'s index.<br />* outer: form union of calling frame's index (or column if on is<br />  specified) with `other`'s index, and sort it.<br />  lexicographically.<br />* inner: form intersection of calling frame's index (or column if<br />  on is specified) with `other`'s index, preserving the order<br />  of the calling's one.<br />* cross: creates the cartesian product from both frames, preserves the order<br />  of the left keys.<br /><br />  .. versionadded:: 1.2.0",
                "type": "{'left', 'right', 'outer', 'inner'}, default 'left'",
                "default": null
            },
            "lsuffix": {
                "description": "Suffix to use from left frame's overlapping columns.",
                "type": "str, default ''",
                "default": null
            },
            "rsuffix": {
                "description": "Suffix to use from right frame's overlapping columns.",
                "type": "str, default ''",
                "default": null
            },
            "sort": {
                "description": "Order result DataFrame lexicographically by the join key. If False,<br />the order of the join key depends on the join type (how keyword).",
                "type": "bool, default False",
                "default": null
            },
            "validate": {
                "description": "If specified, checks if join is of specified type.<br />* \"one_to_one\" or \"1:1\": check if join keys are unique in both left<br />and right datasets.<br />* \"one_to_many\" or \"1:m\": check if join keys are unique in left dataset.<br />* \"many_to_one\" or \"m:1\": check if join keys are unique in right dataset.<br />* \"many_to_many\" or \"m:m\": allowed, but does not result in checks.<br />.. versionadded:: 1.5.0",
                "type": "str",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "merge": {
        "funcdef": "def merge(\n\tself,\n\tright: DataFrame | Series,\n\thow: str,\n\ton: IndexLabel | None,\n\tleft_on: IndexLabel | None,\n\tright_on: IndexLabel | None,\n\tleft_index: bool,\n\tright_index: bool,\n\tsort: bool,\n\tsuffixes: Suffixes,\n\tcopy: bool,\n\tindicator: bool,\n\tvalidate: str | None\n) -> DataFrame",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "round": {
        "funcdef": "def round(\n\tself,\n\tdecimals: int | dict[IndexLabel, int] | Series,\n\t*args,\n\t**kwargs\n) -> DataFrame",
        "description": "Round a DataFrame to a variable number of decimal places.",
        "long_description": null,
        "example": {
            "code": ">>> df = pd.DataFrame([(.21, .32), (.01, .67), (.66, .03), (.21, .18)],",
            "is_executable": false,
            "description": "...                   columns=['dogs', 'cats'])"
        },
        "params": {
            "decimals": {
                "description": "Number of decimal places to round each column to. If an int is<br />given, round each column to the same number of places.<br />Otherwise dict and Series round to variable numbers of places.<br />Column names should be in the keys if `decimals` is a<br />dict-like, or in the index if `decimals` is a Series. Any<br />columns not included in `decimals` will be left as is. Elements<br />of `decimals` which are not columns of the input will be<br />ignored.",
                "type": "int, dict, Series",
                "default": null
            },
            "*args": {
                "description": "Additional keywords have no effect but might be accepted for<br />compatibility with numpy.",
                "type": null,
                "default": null
            },
            "**kwargs": {
                "description": "Additional keywords have no effect but might be accepted for<br />compatibility with numpy.",
                "type": null,
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "corr": {
        "funcdef": "def corr(\n\tself,\n\tmethod: str | Callable[[np.ndarray, np.ndarray], float],\n\tmin_periods: int,\n\tnumeric_only: bool | lib.NoDefault\n) -> DataFrame",
        "description": "Compute pairwise correlation of columns, excluding NA/null values.",
        "long_description": null,
        "example": {
            "code": ">>> def histogram_intersection(a, b):",
            "is_executable": false,
            "description": "...     v = np.minimum(a, b).sum().round(decimals=1)\n...     return v"
        },
        "params": {
            "method": {
                "description": "Method of correlation:<br /><br />* pearson : standard correlation coefficient<br />* kendall : Kendall Tau correlation coefficient<br />* spearman : Spearman rank correlation<br />* callable: callable with input two 1d ndarrays<br />    and returning a float. Note that the returned matrix from corr<br />    will have 1 along the diagonals and will be symmetric<br />    regardless of the callable's behavior.",
                "type": "{'pearson', 'kendall', 'spearman'} or callable",
                "default": null
            },
            "min_periods": {
                "description": "Minimum number of observations required per pair of columns<br />to have a valid result. Currently only available for Pearson<br />and Spearman correlation.",
                "type": "int",
                "default": null
            },
            "numeric_only": {
                "description": "Include only `float`, `int` or `boolean` data.<br /><br />.. versionadded:: 1.5.0<br /><br />.. deprecated:: 1.5.0<br />    The default value of ``numeric_only`` will be ``False`` in a future<br />    version of pandas.",
                "type": "bool, default True",
                "default": "value"
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "cov": {
        "funcdef": "def cov(\n\tself,\n\tmin_periods: int | None,\n\tddof: int | None,\n\tnumeric_only: bool | lib.NoDefault\n) -> DataFrame",
        "description": "Compute pairwise covariance of columns, excluding NA/null values.",
        "long_description": "Compute the pairwise covariance among the series of a DataFrame.<br />The returned data frame is the `covariance matrix<br /><https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns<br />of the DataFrame.<br /><br />Both NA and null values are automatically excluded from the<br />calculation. (See the note below about bias from missing values.)<br />A threshold can be set for the minimum number of<br />observations for each value created. Comparisons with observations<br />below this threshold will be returned as ``NaN``.<br /><br />This method is generally used for the analysis of time series data to<br />understand the relationship between different measures<br />across time.",
        "example": {
            "code": ">>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],",
            "is_executable": false,
            "description": "...                   columns=['dogs', 'cats'])"
        },
        "params": {
            "min_periods": {
                "description": "Minimum number of observations required per pair of columns<br />to have a valid result.",
                "type": "int",
                "default": null
            },
            "ddof": {
                "description": "Delta degrees of freedom.  The divisor used in calculations<br />is ``N - ddof``, where ``N`` represents the number of elements.<br /><br />.. versionadded:: 1.1.0",
                "type": "int, default 1",
                "default": null
            },
            "numeric_only": {
                "description": "Include only `float`, `int` or `boolean` data.<br /><br />.. versionadded:: 1.5.0<br /><br />.. deprecated:: 1.5.0<br />    The default value of ``numeric_only`` will be ``False`` in a future<br />    version of pandas.",
                "type": "bool, default True",
                "default": "value"
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "corrwith": {
        "funcdef": "def corrwith(\n\tself,\n\tother: DataFrame | Series,\n\taxis: Axis,\n\tdrop: bool,\n\tmethod: Literal['pearson', 'kendall', 'spearman'] | Callable[[np.ndarray, np.ndarray], float],\n\tnumeric_only: bool | lib.NoDefault\n) -> Series",
        "description": "Compute pairwise correlation.",
        "long_description": "Pairwise correlation is computed between rows or columns of<br />DataFrame with rows or columns of Series or DataFrame. DataFrames<br />are first aligned along both axes before computing the<br />correlations.",
        "example": {
            "code": ">>> index = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n>>> columns = [\"one\", \"two\", \"three\", \"four\"]\n>>> df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)\n>>> df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)\n>>> df1.corrwith(df2)",
            "is_executable": false,
            "description": "one      1.0\ntwo      1.0\nthree    1.0\nfour     1.0\ndtype: float64"
        },
        "params": {
            "other": {
                "description": "Object with which to compute correlations.",
                "type": "DataFrame, Series",
                "default": null
            },
            "axis": {
                "description": "The axis to use. 0 or 'index' to compute row-wise, 1 or 'columns' for<br />column-wise.",
                "type": "{0 or 'index', 1 or 'columns'}, default 0",
                "default": null
            },
            "drop": {
                "description": "Drop missing indices from result.",
                "type": "bool, default False",
                "default": null
            },
            "method": {
                "description": "Method of correlation:<br /><br />* pearson : standard correlation coefficient<br />* kendall : Kendall Tau correlation coefficient<br />* spearman : Spearman rank correlation<br />* callable: callable with input two 1d ndarrays<br />    and returning a float.",
                "type": "{'pearson', 'kendall', 'spearman'} or callable",
                "default": null
            },
            "numeric_only": {
                "description": "Include only `float`, `int` or `boolean` data.<br /><br />.. versionadded:: 1.5.0<br /><br />.. deprecated:: 1.5.0<br />    The default value of ``numeric_only`` will be ``False`` in a future<br />    version of pandas.",
                "type": "bool, default True",
                "default": "value"
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "Series"
        }
    },
    "count": {
        "funcdef": "def count(\n\tself,\n\taxis: Axis,\n\tlevel: Level,\n\tnumeric_only: bool\n)",
        "description": "Count non-NA cells for each column or row.",
        "long_description": "The values `None`, `NaN`, `NaT`, and optionally `numpy.inf` (depending<br />on `pandas.options.mode.use_inf_as_na`) are considered NA.",
        "example": {
            "code": "Constructing DataFrame from a dictionary:",
            "is_executable": false,
            "description": ""
        },
        "params": {
            "axis": {
                "description": "If 0 or 'index' counts are generated for each column.<br />If 1 or 'columns' counts are generated for each row.",
                "type": "{0 or 'index', 1 or 'columns'}, default 0",
                "default": null
            },
            "level": {
                "description": "If the axis is a `MultiIndex` (hierarchical), count along a<br />particular `level`, collapsing into a `DataFrame`.<br />A `str` specifies the level name.",
                "type": "int or str",
                "default": null
            },
            "numeric_only": {
                "description": "Include only `float`, `int` or `boolean` data.",
                "type": "bool, default False",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "Series or DataFrame"
        }
    },
    "nunique": {
        "funcdef": "def nunique(\n\tself,\n\taxis: Axis,\n\tdropna: bool\n) -> Series",
        "description": "Count number of distinct elements in specified axis.",
        "long_description": "Return Series with number of distinct elements. Can ignore NaN<br />values.",
        "example": {
            "code": ">>> df = pd.DataFrame({'A': [4, 5, 6], 'B': [4, 1, 1]})\n>>> df.nunique()",
            "is_executable": false,
            "description": "A    3\nB    2\ndtype: int64"
        },
        "params": {
            "axis": {
                "description": "The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for<br />column-wise.",
                "type": "{0 or 'index', 1 or 'columns'}, default 0",
                "default": null
            },
            "dropna": {
                "description": "Don't include NaN in the counts.",
                "type": "bool, default True",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "Series"
        }
    },
    "idxmin": {
        "funcdef": "def idxmin(\n\tself,\n\taxis: Axis,\n\tskipna: bool,\n\tnumeric_only: bool\n) -> Series",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "idxmax": {
        "funcdef": "def idxmax(\n\tself,\n\taxis: Axis,\n\tskipna: bool,\n\tnumeric_only: bool\n) -> Series",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "mode": {
        "funcdef": "def mode(\n\tself,\n\taxis: Axis,\n\tnumeric_only: bool,\n\tdropna: bool\n) -> DataFrame",
        "description": "Get the mode(s) of each element along the selected axis.",
        "long_description": "The mode of a set of values is the value that appears most often.<br />It can be multiple values.",
        "example": {
            "code": ">>> df = pd.DataFrame([('bird', 2, 2),",
            "is_executable": false,
            "description": "...                    ('mammal', 4, np.nan),\n...                    ('arthropod', 8, 0),\n...                    ('bird', 2, np.nan)],\n...                   index=('falcon', 'horse', 'spider', 'ostrich'),\n...                   columns=('species', 'legs', 'wings'))"
        },
        "params": {
            "axis": {
                "description": "The axis to iterate over while searching for the mode:<br /><br />* 0 or 'index' : get mode of each column<br />* 1 or 'columns' : get mode of each row.",
                "type": "{0 or 'index', 1 or 'columns'}, default 0",
                "default": null
            },
            "numeric_only": {
                "description": "If True, only apply to numeric columns.",
                "type": "bool, default False",
                "default": null
            },
            "dropna": {
                "description": "Don't consider counts of NaN/NaT.",
                "type": "bool, default True",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "quantile": {
        "funcdef": "def quantile(\n\tself,\n\tq: float | AnyArrayLike | Sequence[float],\n\taxis: Axis,\n\tnumeric_only: bool | lib.NoDefault,\n\tinterpolation: QuantileInterpolation,\n\tmethod: Literal['single', 'table']\n) -> Series | DataFrame",
        "description": "Return values at the given quantile over requested axis.",
        "long_description": null,
        "example": {
            "code": ">>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),",
            "is_executable": false,
            "description": "...                   columns=['a', 'b'])"
        },
        "params": {
            "q": {
                "description": "Value between 0 <= q <= 1, the quantile(s) to compute.",
                "type": "float or array-like, default 0.5 (50% quantile)",
                "default": null
            },
            "axis": {
                "description": "Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise.",
                "type": "{0 or 'index', 1 or 'columns'}, default 0",
                "default": null
            },
            "numeric_only": {
                "description": "If False, the quantile of datetime and timedelta data will be<br />computed as well.<br /><br />.. deprecated:: 1.5.0<br />    The default value of ``numeric_only`` will be ``False`` in a future<br />    version of pandas.",
                "type": "bool, default True",
                "default": "value"
            },
            "interpolation": {
                "description": "This optional parameter specifies the interpolation method to use,<br />when the desired quantile lies between two data points `i` and `j`:<br /><br />* linear: `i + (j - i) * fraction`, where `fraction` is the<br />  fractional part of the index surrounded by `i` and `j`.<br />* lower: `i`.<br />* higher: `j`.<br />* nearest: `i` or `j` whichever is nearest.<br />* midpoint: (`i` + `j`) / 2.",
                "type": "{'linear', 'lower', 'higher', 'midpoint', 'nearest'}",
                "default": null
            },
            "method": {
                "description": "Whether to compute quantiles per-column ('single') or over all columns<br />('table'). When 'table', the only allowed interpolation methods are<br />'nearest', 'lower', and 'higher'.",
                "type": "{'single', 'table'}, default 'single'",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "Series or DataFrame"
        }
    },
    "asfreq": {
        "funcdef": "def asfreq(\n\tself,\n\tfreq: Frequency,\n\tmethod: FillnaOptions | None,\n\thow: str | None,\n\tnormalize: bool,\n\tfill_value: Hashable\n) -> DataFrame",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "resample": {
        "funcdef": "def resample(\n\tself,\n\trule,\n\taxis: Axis,\n\tclosed: str | None,\n\tlabel: str | None,\n\tconvention: str,\n\tkind: str | None,\n\tloffset,\n\tbase: int | None,\n\ton: Level,\n\tlevel: Level,\n\torigin: str | TimestampConvertibleTypes,\n\toffset: TimedeltaConvertibleTypes | None,\n\tgroup_keys: bool | lib.NoDefault\n) -> Resampler",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "to_timestamp": {
        "funcdef": "def to_timestamp(\n\tself,\n\tfreq: Frequency | None,\n\thow: str,\n\taxis: Axis,\n\tcopy: bool\n) -> DataFrame",
        "description": "Cast to DatetimeIndex of timestamps, at *beginning* of period.",
        "long_description": null,
        "example": null,
        "params": {
            "freq": {
                "description": "Desired frequency.",
                "type": "str, default frequency of PeriodIndex",
                "default": null
            },
            "how": {
                "description": "Convention for converting period to timestamp; start of period<br />vs. end.",
                "type": "{'s', 'e', 'start', 'end'}",
                "default": null
            },
            "axis": {
                "description": "The axis to convert (the index by default).",
                "type": "{0 or 'index', 1 or 'columns'}, default 0",
                "default": null
            },
            "copy": {
                "description": "If False then underlying input data is not copied.",
                "type": "bool, default True",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame with DatetimeIndex"
        }
    },
    "to_period": {
        "funcdef": "def to_period(\n\tself,\n\tfreq: Frequency | None,\n\taxis: Axis,\n\tcopy: bool\n) -> DataFrame",
        "description": "Convert DataFrame from DatetimeIndex to PeriodIndex.",
        "long_description": "Convert DataFrame from DatetimeIndex to PeriodIndex with desired<br />frequency (inferred from index if not passed).",
        "example": {
            "code": ">>> idx = pd.to_datetime(",
            "is_executable": false,
            "description": "...     [\n...         \"2001-03-31 00:00:00\",\n...         \"2002-05-31 00:00:00\",\n...         \"2003-08-31 00:00:00\",\n...     ]\n... )"
        },
        "params": {
            "freq": {
                "description": "Frequency of the PeriodIndex.",
                "type": "str, default",
                "default": null
            },
            "axis": {
                "description": "The axis to convert (the index by default).",
                "type": "{0 or 'index', 1 or 'columns'}, default 0",
                "default": null
            },
            "copy": {
                "description": "If False then underlying input data is not copied.",
                "type": "bool, default True",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame with PeriodIndex"
        }
    },
    "isin": {
        "funcdef": "def isin(\n\tself,\n\tvalues: Series | DataFrame | Sequence | Mapping\n) -> DataFrame",
        "description": "Whether each element in the DataFrame is contained in values.",
        "long_description": null,
        "example": {
            "code": ">>> df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},",
            "is_executable": false,
            "description": "...                   index=['falcon', 'dog'])"
        },
        "params": {
            "values": {
                "description": "The result will only be true at a location if all the<br />labels match. If `values` is a Series, that's the index. If<br />`values` is a dict, the keys must be the column names,<br />which must match. If `values` is a DataFrame,<br />then both the index and column labels must match.",
                "type": "iterable, Series, DataFrame or dict",
                "default": null
            }
        },
        "raises": [],
        "returns": {
            "name": null,
            "type": "DataFrame"
        }
    },
    "values": {
        "funcdef": "def values(\n\tself\n) -> np.ndarray",
        "description": "Return a Numpy representation of the DataFrame.",
        "long_description": ".. warning::<br /><br />   We recommend using :meth:`DataFrame.to_numpy` instead.<br /><br />Only the values in the DataFrame will be returned, the axes labels<br />will be removed.",
        "example": {
            "code": "A DataFrame where all columns are the same type (e.g., int64) results\nin an array of the same type.",
            "is_executable": false,
            "description": ""
        },
        "params": {},
        "raises": [],
        "returns": {
            "name": null,
            "type": "numpy.ndarray"
        }
    },
    "ffill": {
        "funcdef": "def ffill(\n\tself,\n\taxis: None | Axis,\n\tinplace: bool,\n\tlimit: None | int,\n\tdowncast: dict | None\n) -> DataFrame | None",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "bfill": {
        "funcdef": "def bfill(\n\tself,\n\taxis: None | Axis,\n\tinplace: bool,\n\tlimit: None | int,\n\tdowncast\n) -> DataFrame | None",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "clip": {
        "funcdef": "def clip(\n\tself: DataFrame,\n\tlower: float | None,\n\tupper: float | None,\n\taxis: Axis | None,\n\tinplace: bool,\n\t*args,\n\t**kwargs\n) -> DataFrame | None",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "interpolate": {
        "funcdef": "def interpolate(\n\tself: DataFrame,\n\tmethod: str,\n\taxis: Axis,\n\tlimit: int | None,\n\tinplace: bool,\n\tlimit_direction: str | None,\n\tlimit_area: str | None,\n\tdowncast: str | None,\n\t**kwargs\n) -> DataFrame | None",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "where": {
        "funcdef": "def where(\n\tself,\n\tcond,\n\tother,\n\tinplace: bool,\n\taxis: Axis | None,\n\tlevel: Level,\n\terrors: IgnoreRaise | lib.NoDefault,\n\ttry_cast: bool | lib.NoDefault\n) -> DataFrame | None",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    },
    "mask": {
        "funcdef": "def mask(\n\tself,\n\tcond,\n\tother,\n\tinplace: bool,\n\taxis: Axis | None,\n\tlevel: Level,\n\terrors: IgnoreRaise | lib.NoDefault,\n\ttry_cast: bool | lib.NoDefault\n) -> DataFrame | None",
        "description": null,
        "long_description": null,
        "example": null,
        "params": {},
        "raises": [],
        "returns": null
    }
}